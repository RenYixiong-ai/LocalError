{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import copy\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# 定义数据加载函数\n",
    "def get_data():\n",
    "    # 定义数据转换（将图像转换为Tensor并标准化）\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),  # 转换为Tensor\n",
    "        transforms.Normalize((0.5,), (0.5,))  # 标准化（均值0.5，标准差0.5）\n",
    "    ])\n",
    "\n",
    "    # 下载和加载训练集和测试集\n",
    "    trainset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "    testset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "    # 使用DataLoader加载数据\n",
    "    trainloader = DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "    testloader = DataLoader(testset, batch_size=64, shuffle=False)\n",
    "    return trainloader, testloader\n",
    "\n",
    "# 定义模型\n",
    "class SingleLayerNetwork(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(SingleLayerNetwork, self).__init__()\n",
    "        # 定义线性层\n",
    "        self.fc = nn.Linear(input_size, output_size)\n",
    "        # 定义ReLU激活函数\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "# 定义模型\n",
    "class MultiLayerNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MultiLayerNetwork, self).__init__()\n",
    "        self.layers = nn.ModuleList()  # 用于存储逐步添加的网络层\n",
    "\n",
    "    def add(self, layer):\n",
    "        # 添加已训练好的网络层到ModuleList中\n",
    "        self.layers.append(copy.deepcopy(layer))\n",
    "\n",
    "    def pop(self):\n",
    "        \"\"\"删除 self.layers 中的最后一个网络层\"\"\"\n",
    "        if len(self.layers) > 0:\n",
    "            last_layer = self.layers[-1]  # 获取最后一层\n",
    "            del self.layers[-1]  # 手动删除\n",
    "            return last_layer  # 返回被删除的层\n",
    "        else:\n",
    "            print(\"Warning: No layers to remove.\")\n",
    "            return None\n",
    "\n",
    "    def forward(self, x, n_layers=None, return_intermediate=False):\n",
    "        outputs = []\n",
    "        \n",
    "        # 逐层计算输出\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            x = layer(x)\n",
    "            if return_intermediate and (n_layers is None or i < n_layers):\n",
    "                outputs.append(x)\n",
    "            if i == n_layers:\n",
    "                break\n",
    "        \n",
    "        if return_intermediate:\n",
    "            return outputs\n",
    "        else:\n",
    "            return x\n",
    "        \n",
    "# 定义读出头网络\n",
    "class ReadoutHead(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(ReadoutHead, self).__init__()\n",
    "        # 初始化权重为高斯分布，且权重不可训练\n",
    "        self.weight = nn.Parameter(torch.randn(input_size, output_size) * 0.01, requires_grad=False)\n",
    "        self.bias = nn.Parameter(torch.zeros(output_size), requires_grad=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 线性变换：y = xW + b\n",
    "        return torch.matmul(x, self.weight) + self.bias\n",
    "    \n",
    "# 定义训练流程\n",
    "def train_with_readout(fixed_network, target_network, readout_head, data_loader, optimizer, criterion, device):\n",
    "    if fixed_network is not None:\n",
    "        fixed_network.eval()    # 固定网络不训练\n",
    "    target_network.train()      # 目标网络训练\n",
    "    total_loss = 0\n",
    "\n",
    "    for inputs, labels in data_loader:\n",
    "        inputs = inputs.view(inputs.shape[0], -1)  # 将图像展平\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # 如果固定网络不为空，数据先通过固定网络（不计算梯度）\n",
    "        outputs = inputs\n",
    "        if fixed_network is not None:\n",
    "            with torch.no_grad():\n",
    "                outputs = fixed_network(inputs)\n",
    "\n",
    "\n",
    "        # 数据通过目标网络\n",
    "        target_outputs = target_network(outputs)\n",
    "\n",
    "        # 数据通过读出头网络\n",
    "        logits = readout_head(target_outputs)\n",
    "\n",
    "        # 计算交叉熵损失\n",
    "        loss = criterion(logits, labels)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # 反向传播优化目标网络\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    return total_loss / len(data_loader)\n",
    "\n",
    "# 定义评估函数\n",
    "def evaluate_accuracy(target_network, data_loader, device, readout_head=None):\n",
    "    # 固定网络、目标网络和读出头网络都设置为评估模式\n",
    "    target_network.eval()\n",
    "    if readout_head is not None:\n",
    "        readout_head.eval()\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():  # 不计算梯度\n",
    "        for inputs, labels in data_loader:\n",
    "            inputs = inputs.view(inputs.shape[0], -1)  # 将图像展平\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            # 数据通过目标网络\n",
    "            target_outputs = target_network(inputs)\n",
    "\n",
    "            if readout_head is not None:\n",
    "                # 数据通过读出头网络\n",
    "                target_outputs = readout_head(target_outputs)\n",
    "\n",
    "            # 预测类别\n",
    "            _, predicted = torch.max(target_outputs, dim=1)  # 取概率最大的类别\n",
    "\n",
    "            # 统计正确预测的数量\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    # 计算并返回准确率\n",
    "    accuracy = correct / total\n",
    "    return accuracy\n",
    "\n",
    "# 定义训练函数\n",
    "def estimate_alpha_mle(data, x_min):\n",
    "    \"\"\"\n",
    "    使用最大似然估计（MLE）计算幂律指数 α\n",
    "    :param data: 观测数据（numpy 数组）\n",
    "    :param x_min: 设定的最小阈值，幂律分布从 x_min 开始适用\n",
    "    :return: 估计的 α\n",
    "    \"\"\"\n",
    "    filtered_data = data[data >= x_min]  # 只选取大于等于 x_min 的数据\n",
    "    n = len(filtered_data)  # 数据点数\n",
    "    alpha = 1 + n / np.sum(np.log(filtered_data / x_min))\n",
    "    return alpha\n",
    "\n",
    "# 定义函数计算特征值\n",
    "def get_eigenvalues(data):\n",
    "    data = data - np.mean(data, axis=0)\n",
    "    # 计算数据的协方差矩阵\n",
    "    covariance_matrix = np.cov(data, rowvar=False)\n",
    "    \n",
    "    # 计算协方差矩阵的特征值\n",
    "    eigenvalues, _ = np.linalg.eig(covariance_matrix)\n",
    "    \n",
    "    # 对特征值进行排序\n",
    "    eigenvalues = np.sort(eigenvalues)[::-1]\n",
    "    return eigenvalues\n",
    "\n",
    "# 定义函数计算 α 和 R^2\n",
    "def get_alpha_r(eigenvalues):\n",
    "    # 估计幂律指数 α\n",
    "    slope = estimate_alpha_mle(eigenvalues, 0.000001)\n",
    "\n",
    "    # 计算R^2\n",
    "    # 假设 eigenvalues 是特征值数组 (已按降序排列)\n",
    "    explained_variance_ratio = eigenvalues / np.sum(eigenvalues)  # 计算解释方差比例\n",
    "    cumulative_variance = np.cumsum(explained_variance_ratio)  # 计算累计贡献率\n",
    "\n",
    "    # 选择前 k 个主成分，使得累计贡献率达到 95%\n",
    "    k = np.argmax(cumulative_variance >= 0.95) + 1  # 找到累计方差贡献率 >= 95% 的最小维度\n",
    "    R2_95 = cumulative_variance[10]\n",
    "    return slope, R2_95, k\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "trainloader, testloader = get_data()\n",
    "\n",
    "tot_NN = MultiLayerNetwork()\n",
    "input_size = 28*28\n",
    "size_range = [1000, 1000, 1000, 1000, 1000]\n",
    "for k, output_size in enumerate(size_range):\n",
    "    # 初始化一个单层网络\n",
    "    Single_NN = SingleLayerNetwork(input_size, output_size).to(device)\n",
    "    optimizer = optim.Adam(Single_NN.parameters(), lr=0.001)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    readout_head = ReadoutHead(output_size, 10).to(device)\n",
    "\n",
    "    # 训练该单层网络\n",
    "    for epoch in range(15):\n",
    "        Single_NN.train()  # 设为训练模式，启用 Dropout、BatchNorm\n",
    "        loss = train_with_readout(fixed_network=tot_NN, target_network=Single_NN, readout_head=readout_head, data_loader=trainloader, optimizer=optimizer, criterion=criterion, device=device)\n",
    "\n",
    "        # 分析网络的特征\n",
    "        tot_NN.add(Single_NN)\n",
    "        eva_value = evaluate_accuracy(target_network=tot_NN, readout_head=readout_head, data_loader=testloader, device=device)\n",
    "\n",
    "        tot_NN.eval()  # 设为评估模式，不启用 Dropout、BatchNorm\n",
    "        output_list = []\n",
    "        with torch.no_grad():  # 不计算梯度，加速推理\n",
    "            for inputs, labels in trainloader:\n",
    "                inputs = inputs.view(inputs.shape[0], -1)  # 将图像展平\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                output = tot_NN(inputs, 3)  # 前向传播\n",
    "                output_list.append(output.cpu().numpy())  # 转换为 NumPy 并保存\n",
    "\n",
    "        # 拼接成一个完整的 NumPy 数组\n",
    "        final_output = np.vstack(output_list) \n",
    "        eigenvalues = get_eigenvalues(final_output)\n",
    "        slope, R2_95, k = get_alpha_r(eigenvalues)\n",
    "        tot_NN.pop()\n",
    "\n",
    "        print(\"each epoch\", loss, eva_value, slope, R2_95, k)\n",
    "\n",
    "    input_size = output_size\n",
    "    tot_NN.add(Single_NN)\n",
    "\n",
    "    eva_value = evaluate_accuracy(target_network=tot_NN, readout_head=readout_head, data_loader=testloader, device=device)\n",
    "    print(\"eval\", eva_value)\n",
    "\n",
    "tot_NN.add(readout_head)\n",
    "\n",
    "final_eval = evaluate_accuracy(target_network=tot_NN, data_loader=testloader, device=device)\n",
    "print(final_eval)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "normal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
