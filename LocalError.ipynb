{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 项目说明\n",
    "该项目复现local error训练，通过对深度网络的每一层单独计算准确性，最终实现整体的训练。\n",
    "\n",
    "这是一种新的网络训练方式，可以调控网络每一层的流形，从而实现可解释性的分析。\n",
    "\n",
    "文献参考：\n",
    "* [Deep Supervised Learning Using Local Errors](https://www.frontiersin.org/journals/neuroscience/articles/10.3389/fnins.2018.00608/full)\n",
    "* [Relationship between manifold smoothness and adversarial vulnerability in deep learning with local errors](https://cpb.iphy.ac.cn/EN/10.1088/1674-1056/abd68e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  数据输入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 定义数据转换（将图像转换为Tensor并标准化）\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # 转换为Tensor\n",
    "    transforms.Normalize((0.5,), (0.5,))  # 标准化（均值0.5，标准差0.5）\n",
    "])\n",
    "\n",
    "# 下载和加载训练集和测试集\n",
    "trainset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "testset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# 使用DataLoader加载数据\n",
    "trainloader = DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "testloader = DataLoader(testset, batch_size=64, shuffle=False)\n",
    "\n",
    "# 查看训练数据的一部分\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = next(dataiter)\n",
    "print(images.shape)  # 输出形状，应该是[64, 1, 28, 28]，即64张28x28的图像\n",
    "print(labels.shape)  # 输出标签形状，应该是[64]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 网络构建\n",
    "\n",
    "单层网络和粘合多层网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class SingleLayerNetwork(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(SingleLayerNetwork, self).__init__()\n",
    "        # 定义线性层\n",
    "        self.fc = nn.Linear(input_size, output_size)\n",
    "        # 定义ReLU激活函数\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        x = self.relu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "class MultiLayerNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MultiLayerNetwork, self).__init__()\n",
    "        self.layers = nn.ModuleList()  # 用于存储逐步添加的网络层\n",
    "\n",
    "    def add(self, layer):\n",
    "        # 添加已训练好的网络层到ModuleList中\n",
    "        self.layers.append(copy.deepcopy(layer))\n",
    "\n",
    "\n",
    "    def forward(self, x, return_intermediate=False, n_layers=None):\n",
    "        outputs = []\n",
    "        \n",
    "        # 逐层计算输出\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            x = layer(x)\n",
    "            if return_intermediate and (n_layers is None or i < n_layers):\n",
    "                outputs.append(x)\n",
    "        \n",
    "        if return_intermediate:\n",
    "            return outputs\n",
    "        else:\n",
    "            return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练方法\n",
    "通过读出头训练目标网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# 定义读出头网络\n",
    "class ReadoutHead(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(ReadoutHead, self).__init__()\n",
    "        # 初始化权重为高斯分布，且权重不可训练\n",
    "        self.weight = nn.Parameter(torch.randn(input_size, output_size) * 0.01, requires_grad=False)\n",
    "        self.bias = nn.Parameter(torch.zeros(output_size), requires_grad=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 线性变换：y = xW + b\n",
    "        return torch.matmul(x, self.weight) + self.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义训练流程\n",
    "def train_with_readout(fixed_network, target_network, readout_head, data_loader, optimizer, criterion, device):\n",
    "    if fixed_network is not None:\n",
    "        fixed_network.eval()  # 固定网络不训练\n",
    "    target_network.train()  # 目标网络训练\n",
    "    total_loss = 0\n",
    "\n",
    "    for inputs, labels in data_loader:\n",
    "        inputs = inputs.view(inputs.shape[0], -1)  # 将图像展平\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # 如果固定网络不为空，数据先通过固定网络（不计算梯度）\n",
    "        outputs = inputs\n",
    "        if fixed_network is not None:\n",
    "            with torch.no_grad():\n",
    "                outputs = fixed_network(inputs)\n",
    "\n",
    "\n",
    "        # 数据通过目标网络\n",
    "        target_outputs = target_network(outputs)\n",
    "\n",
    "        # 数据通过读出头网络\n",
    "        logits = readout_head(target_outputs)\n",
    "\n",
    "        # 计算交叉熵损失\n",
    "        loss = criterion(logits, labels)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # 反向传播优化目标网络\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    return total_loss / len(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_NN = MultiLayerNetwork()\n",
    "Single_NN = SingleLayerNetwork(28*28, 1000).to(device)\n",
    "# 定义优化器和损失函数\n",
    "optimizer = optim.Adam(Single_NN.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "readout_head = ReadoutHead(1000, 10).to(device)\n",
    "\n",
    "for epoch in range(10):\n",
    "    loss = train_with_readout(fixed_network=None, target_network=Single_NN, readout_head=readout_head, data_loader=trainloader, optimizer=optimizer, criterion=criterion, device=device)\n",
    "    print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 测试正确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.923"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def evaluate_accuracy(target_network, readout_head, data_loader, device):\n",
    "    # 固定网络、目标网络和读出头网络都设置为评估模式\n",
    "    target_network.eval()\n",
    "    readout_head.eval()\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():  # 不计算梯度\n",
    "        for inputs, labels in data_loader:\n",
    "            inputs = inputs.view(inputs.shape[0], -1)  # 将图像展平\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = inputs  # 否则直接使用原始输入\n",
    "\n",
    "            # 数据通过目标网络\n",
    "            target_outputs = target_network(outputs)\n",
    "\n",
    "            # 数据通过读出头网络\n",
    "            logits = readout_head(target_outputs)\n",
    "\n",
    "            # 预测类别\n",
    "            _, predicted = torch.max(logits, dim=1)  # 取概率最大的类别\n",
    "\n",
    "            # 统计正确预测的数量\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    # 计算并返回准确率\n",
    "    accuracy = correct / total\n",
    "    return accuracy\n",
    "\n",
    "tot_NN.add(Single_NN)\n",
    "evaluate_accuracy(target_network=tot_NN, readout_head=readout_head, data_loader=testloader, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 构建K层的神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.39017897546450214\n",
      "0.240037655334737\n",
      "0.18679260970877687\n",
      "0.1542889989420041\n",
      "0.13292533516296065\n",
      "0.11369331996403396\n",
      "0.09988672153821695\n",
      "0.09081291814130157\n",
      "0.0819651381656734\n",
      "0.07396197762749375\n",
      "0.06720978218013607\n",
      "0.061354180634109134\n",
      "0.05681880087311715\n",
      "0.053389444656824984\n",
      "0.047691436567858084\n",
      "0.04489018160677048\n",
      "0.04091853250278783\n",
      "0.03896126953506671\n",
      "0.03703258924239845\n",
      "0.03283419119475135\n",
      "0.031541944070131396\n",
      "0.029273753394750055\n",
      "0.027342400601459368\n",
      "0.025680544145002183\n",
      "0.023831345072176966\n",
      "0.0222530340716771\n",
      "0.020689605092351782\n",
      "0.019981677201750286\n",
      "0.018256018783570502\n",
      "0.017523002866129362\n",
      "evsl 0.9805\n",
      "0.08407890707497541\n",
      "0.03865458690187298\n",
      "0.03232587335308224\n",
      "0.02949823846217144\n",
      "0.02302456708152606\n",
      "0.025489770301875665\n",
      "0.01771544928868135\n",
      "0.021898657428793683\n",
      "0.017370043202093212\n",
      "0.01815270947103568\n",
      "0.019246937517409652\n",
      "0.013795591634961987\n",
      "0.01341516855989248\n",
      "0.014731566840778648\n",
      "0.012769270338041767\n",
      "0.00964233705460523\n",
      "0.011626428903832033\n",
      "0.014774192648094384\n",
      "0.007143067458321576\n",
      "0.012987051317253662\n",
      "0.009960866095559268\n",
      "0.009782749866681414\n",
      "0.007746756494250172\n",
      "0.008514539130144329\n",
      "0.009180088513689314\n",
      "0.00822339182337973\n",
      "0.0074421861815980464\n",
      "0.007403740767059919\n",
      "0.008086406831242844\n",
      "0.005072137793005949\n",
      "evsl 0.9828\n",
      "0.1032804373460935\n",
      "0.07853591372140907\n",
      "0.055692855818508226\n",
      "0.060097347482507245\n",
      "0.04242894217160061\n",
      "0.0524502590481484\n",
      "0.040180717286545944\n",
      "0.03997368825745294\n",
      "0.02810939846695913\n",
      "0.04803723229201811\n",
      "0.03916157635481951\n",
      "0.020283537711134076\n",
      "0.034293089663883475\n",
      "0.03428961750697902\n",
      "0.02143209790880857\n",
      "0.025748654085889076\n",
      "0.027001455121105578\n",
      "0.01727552087389742\n",
      "0.03087284186449013\n",
      "0.01990826523819148\n",
      "0.027930041961109313\n",
      "0.022301134010763574\n",
      "0.001867498543951844\n",
      "0.018403856205304703\n",
      "0.01349463881446168\n",
      "0.03276326990249604\n",
      "0.012619941655663809\n",
      "0.0060358711764990905\n",
      "0.005097227217600485\n",
      "0.038334473687152516\n",
      "evsl 0.9822\n",
      "0.6906768816684744\n",
      "0.37222104328177463\n",
      "0.26336724996546534\n",
      "0.3597005000561696\n",
      "0.3651610587966975\n",
      "0.32047557511965363\n",
      "0.1439460541870042\n",
      "0.03963872059576039\n",
      "0.301713610774895\n",
      "0.10908330436395074\n",
      "0.1358784771182768\n",
      "0.13183701471795228\n",
      "0.06474671328315061\n",
      "0.13255162556113934\n",
      "0.16784469352068337\n",
      "0.10124797861713336\n",
      "0.13399144931078183\n",
      "0.11349723743577823\n",
      "0.16147131197996487\n",
      "0.007150084733454657\n",
      "0.06200325158613323\n",
      "0.12986029033213536\n",
      "0.04108756742497751\n",
      "0.07144649806760077\n",
      "0.20631860110805486\n",
      "0.040284201534572184\n",
      "0.10068317466993322\n",
      "0.0926071321691023\n",
      "0.027342253978213243\n",
      "0.01158454472909246\n",
      "evsl 0.9798\n",
      "4.315375594370565\n",
      "1.9835387435294927\n",
      "2.0009730068358933\n",
      "1.9615488926739073\n",
      "2.4940988178700527\n",
      "0.9589297654532166\n",
      "1.2176934833973965\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "evsl 0.9824\n",
      "0.9824\n"
     ]
    }
   ],
   "source": [
    "tot_NN = MultiLayerNetwork()\n",
    "input_size = 28*28\n",
    "size_range = [1000, 1000, 1000, 1000, 1000]\n",
    "for k, output_size in enumerate(size_range):\n",
    "    # 初始化一个单层网络\n",
    "    Single_NN = SingleLayerNetwork(input_size, output_size).to(device)\n",
    "    optimizer = optim.Adam(Single_NN.parameters(), lr=0.001)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    readout_head = ReadoutHead(output_size, 10).to(device)\n",
    "\n",
    "    # 训练该单层网络\n",
    "    for epoch in range(30):\n",
    "        loss = train_with_readout(fixed_network=tot_NN, target_network=Single_NN, readout_head=readout_head, data_loader=trainloader, optimizer=optimizer, criterion=criterion, device=device)\n",
    "        print(loss)\n",
    "\n",
    "    input_size = output_size\n",
    "    tot_NN.add(Single_NN)\n",
    "\n",
    "    eva_value = evaluate_accuracy(target_network=tot_NN, readout_head=readout_head, data_loader=testloader, device=device)\n",
    "    print(\"evsl\", eva_value)\n",
    "    \n",
    "final_eval = evaluate_accuracy(target_network=tot_NN, readout_head=readout_head, data_loader=testloader, device=device)\n",
    "print(final_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'VisibleDeprecationWarning' from 'numpy' (unknown location)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ren97\\miniconda3\\envs\\normal\\Lib\\site-packages\\matplotlib\\cbook.py:27\u001b[39m\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mnumpy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m VisibleDeprecationWarning  \u001b[38;5;66;03m# numpy >= 1.25\u001b[39;00m\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'numpy.exceptions'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[34;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[34;01mnp\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[34;01mplt\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[34;01mscipy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mstats\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[34;01mstats\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34mestimate_alpha_mle\u001b[39m(data, x_min):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ren97\\miniconda3\\envs\\normal\\Lib\\site-packages\\matplotlib\\__init__.py:161\u001b[39m\n\u001b[32m    157\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mpackaging\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mversion\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m parse \u001b[38;5;28;01mas\u001b[39;00m parse_version\n\u001b[32m    159\u001b[39m \u001b[38;5;66;03m# cbook must import matplotlib only within function\u001b[39;00m\n\u001b[32m    160\u001b[39m \u001b[38;5;66;03m# definitions, so it is safe to import from it here.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m161\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _api, _version, cbook, _docstring, rcsetup\n\u001b[32m    162\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_api\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MatplotlibDeprecationWarning\n\u001b[32m    163\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mrcsetup\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cycler  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ren97\\miniconda3\\envs\\normal\\Lib\\site-packages\\matplotlib\\cbook.py:29\u001b[39m\n\u001b[32m     27\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mnumpy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m VisibleDeprecationWarning  \u001b[38;5;66;03m# numpy >= 1.25\u001b[39;00m\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mnumpy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m VisibleDeprecationWarning\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[34;01mmatplotlib\u001b[39;00m\n\u001b[32m     32\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _api, _c_internal_utils\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'VisibleDeprecationWarning' from 'numpy' (unknown location)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "\n",
    "def estimate_alpha_mle(data, x_min):\n",
    "    \"\"\"\n",
    "    使用最大似然估计（MLE）计算幂律指数 α\n",
    "    :param data: 观测数据（numpy 数组）\n",
    "    :param x_min: 设定的最小阈值，幂律分布从 x_min 开始适用\n",
    "    :return: 估计的 α\n",
    "    \"\"\"\n",
    "    filtered_data = data[data >= x_min]  # 只选取大于等于 x_min 的数据\n",
    "    n = len(filtered_data)  # 数据点数\n",
    "    alpha = 1 + n / np.sum(np.log(filtered_data / x_min))\n",
    "    return alpha\n",
    "\n",
    "# 生成一个模拟的幂律分布数据\n",
    "np.random.seed(42)\n",
    "n_samples = 1000\n",
    "alpha_true = 2.5  # 真实幂律指数\n",
    "x_min = 1  # 设定最小阈值\n",
    "\n",
    "# 生成服从幂律分布的数据（使用逆变换采样法）\n",
    "random_values = np.random.uniform(size=n_samples)\n",
    "data = x_min * (1 - random_values) ** (-1 / (alpha_true - 1))\n",
    "\n",
    "# 估计幂律指数 α\n",
    "alpha_estimated = estimate_alpha_mle(data, x_min)\n",
    "print(f\"估计的幂律指数 α: {alpha_estimated:.4f}\")\n",
    "\n",
    "# 绘制直方图（对数-对数图）\n",
    "plt.figure(figsize=(8, 6))\n",
    "hist, bins, _ = plt.hist(data, bins=50, density=True, alpha=0.6, color='b', label='数据直方图')\n",
    "bin_centers = (bins[:-1] + bins[1:]) / 2\n",
    "\n",
    "# 拟合一条直线（检查幂律特性）\n",
    "slope, intercept, _, _, _ = stats.linregress(np.log(bin_centers), np.log(hist))\n",
    "plt.plot(bin_centers, np.exp(intercept) * bin_centers**slope, 'r--', label=f'拟合: slope={slope:.2f}')\n",
    "\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('P(x)')\n",
    "plt.title('幂律分布的对数-对数图')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "normal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
